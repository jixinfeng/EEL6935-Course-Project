\documentclass[aspectratio=169]{beamer}
\usetheme{metropolis}
\usecolortheme{default}

\usepackage{coffee4}
\usepackage{color}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{tabularx, booktabs}
\usepackage[lined]{algorithm2e}

% For text bubble
\usepackage{tikz}
\usetikzlibrary{shapes,fit,backgrounds}
\newcounter{mybox}
\newcommand\tikzmark[1]{%
  \tikz[remember picture,overlay] \node[inner xsep=0pt] (#1) {};
}
\newcommand<>\ColorBox[2][]{%
\stepcounter{mybox}%
\node[rectangle callout,rounded corners=5pt,draw=cyan,fill=cyan!20,align=left,#1] (box\themybox) {#2};
}

% metropolis beamer theme can be found in GitHub:
% https://github.com/matze/mtheme
% coffee stain package can be found at:
% http://hanno-rein.de/archives/349

\title{Improved Neural Relation Detection for\\ Knowledge Base Question Answering}
\author{Caleb Bryant\inst{1} Jixin Feng\inst{2}}
\institute{
Department of \\
  \inst{1}%
  Computer \& Information Science \& Engineering \\
  \inst{2}
  Electrical \& Computer Engineering\\
  University of Florida, Gainesville, FL}
\date{April 06 2018}

\begin{document}
\frame{\titlepage}

\begin{frame}
\frametitle{Paper Outline}
    \center\includegraphics[width=0.7\textwidth]{figure/paper_title}
    \begin{itemize}
        \item Introduction
        \item Relation Extraction \& Relation Detection
        \item Different Granularity in KB Relations
        \item Proposed Improved Relation Detection
        \item KBQA Enhanced by Relation Detection
        \item Experiment \& Conclusion
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{What is Knowledge Base?}
    \begin{columns}
    \begin{column}{0.55\textwidth}
    \includegraphics[width=\textwidth]{figure/KB_WS}
    % Picture Credit:
    % https://www.researchgate.net/publication/228457497_Query-Independent_Learning_to_Rank_for_RDF_Entity_Search
    \end{column}
    \begin{column}{0.45\textwidth}
    A knowledge base (KB) is a technology used to store complex 
    {\bf structured} and {\bf unstructured} information used by a computer 
    system. \\\hspace*{\fill}--{\it Wikipedia}\\
    
    It stores and manages the knowledge tuples:
    \texttt{<entity-relation-entity>}
    
    A knowledge base can be represented as graph 
    $\mathcal{G}(\mathcal{V},\mathcal{E})$, 
    if we treat entities as vertices and relations as edges.
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\frametitle{What is a Question Answering System?}
    \begin{columns}
    \begin{column}{0.5\textwidth}
    \includegraphics[width=\textwidth]{figure/KB_BO}\\
    % Picture Credit:
    % https://www.semanticscholar.org/paper/Semantic-Parsing-on-Freebase-from-Question-Answer-Berant-Chou/042db0977555fcd7d5eac67b26695cd918ecb44c
    Question answering (QA) is a computer systems that can automatically answer questions posed by humans in natural language. QA systems often convert their input into a structured form which can be used to query a KB.
    \end{column}
    \begin{column}{0.5\textwidth}
    \includegraphics[width=\textwidth]{figure/IBM-Watson-Logo}
    % Picture Credit:
    % http://www.businessinsider.com/ibms-supercomputer-can-now-analyze-your-personality-based-on-a-writing-sample-heres-how-you-try-it-2015-7
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\frametitle{What is a Question Answering System?}
    \begin{columns}
    \begin{column}{0.35\textwidth}
    \begin{itemize}
    \item {\bf IBM Watson} is an automated QA system
    \item Defeated the two greatest Jeopardy! champions
    \item Won the match, outscoring both opponents combined
    \end{itemize}
    \end{column}
    \begin{column}{0.65\textwidth}
    \includegraphics[width=\textwidth]{figure/Watson}
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\frametitle{Introduction}
    \center\includegraphics[width=0.8\textwidth]{figure/fig1}
    \begin{itemize}
    \item KBQA systems answer questions by obtaining information from KB tuples\\
    \item \texttt{input question} $\rightarrow$ \texttt{KB query} $\rightarrow$ \texttt{answer}
    \item Questions can be single-relation questions or multiple-relation questions
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Introduction}
    \includegraphics[width=\textwidth]{figure/fig1_big}
\end{frame}


\begin{frame}
\frametitle{Introduction}
    This paper focuses on improving relation detection.
    \begin{itemize}
        \onslide<1->{
        \item General relation detection has been well studied in NLP
        \begin{itemize}
            \item Most research typically not KBQA driven
            \item Significant gap between previous work and current needs
        \end{itemize}
        \item Number of target relations is limited in most research papers
        \begin{itemize}
            \item Often attempt detecting $\leq 100$ relations
            \item Even a small KB may contain $\geq 6000$ relations
        \end{itemize}
        \item Multiple relation questions require a chain of prediction
        \item Relation detection in KBQA often becomes a {\bf zero-shot learning} task}
        \onslide<3->{
        \item {\bf Conclusion:} KB relation detection is much harder
        }
    \end{itemize}
    \onslide<2>{
    \begin{tikzpicture}[remember picture,overlay]
    \ColorBox[xshift=7cm,yshift=4.8cm]{
        Zero-shot learning is being able to solve a \\
        task despite not having received any training \\
        examples of that task. For a concrete example, \\
        imagine recognizing a category of object in \\
        photos without ever having seen a photo of \\
        that kind of object before. If you've read a \\
        very detailed description of a cat, you might \\
        be able to tell what a cat is in a photograph \\
        the first time you see it.\\
        \hspace*{\fill}--{\it Ian Goodfellow}}
        % https://www.quora.com/What-is-zero-shot-learning
    \end{tikzpicture}}
\end{frame}

\begin{frame}
\frametitle{Relation Extraction}
    \begin{itemize}
    \item A related problem from the Information Extraction community
    \item \textbf{The problem:} given a natural language document and all entity occurrences inside it, find all of the relationships encoded within the document.
    \item RE usually formulated as classification task
    \begin{itemize}
       \item  Classify all possible \texttt{<entity1, paragraph, entity2>} vectors
       \item Relationships with high enough confidence are collected
        \item Traditional RE relies on large amount of hand-crafted features
        \item Impovements from deep learning research: word embeddings, CNN, LSTM, etc.
    \end{itemize}\pause
    \item Traditionally assumes closed set of relation types to avoid zero-shot learning
    \begin{itemize}
        \item Rarely goes beyond $\geq 100$ features
        \item Needs to be trained in supervised way
    \end{itemize}
    \item Assumes two argument entities are both available
    \begin{itemize}
        \item For QA, only single argument is available
    \end{itemize}
    \item Relation extraction (RE) usually works on small, pre-defined relation sets
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Relation Detection}
    \begin{itemize}
       \item The focus of this paper
       \item \textbf{The problem:} given a question and a relationship type, output the probability of that relationship being encoded in the question
        \item Large relation vocabulary/open relation sets needed to support RD task
        \item Fits the goal of open-domain question answering
        \item Need to deal with zero-shot learning:
        \begin{itemize}
            \item Treat questions and potential relationships as sequences and use \\
            {\bf sequence matching and ranking}
        \end{itemize}
        \item Matching and ranking works well because relation names usually form meaningful word sequences\pause
        \item This paper focuses on improving RD
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Different Granularity in KB Relations}
    \begin{itemize}
        \item {\bf Goal:} Formulate KB relation detection as sequence matching problem
        \item Different types of relationship representation
        \begin{itemize}
            \item Relation as a Single Token - use KB embeddings! ({\it relation-level})
            \item Relation as a Word Sequence - use word embeddings! ({\it word-level})
        \end{itemize}
    \end{itemize}
    \includegraphics[width=\textwidth]{figure/table1_big}
\end{frame}

\begin{frame}
\frametitle{Relation as a Single Token}
    \begin{itemize}
        \item Each relation is treated as a unique token
        \item This suffers from the low relation coverage due to limited training data
        \item For example, matching \texttt{episodes\_written} and 
            \texttt{starring\_roles} will be very hard if no examples appear 
            in the training data
        \item Relation embedding will be a random vector, not comparable to question embedding
    \end{itemize}
    \center\includegraphics[width=0.8\textwidth]{figure/fig1}
\end{frame}

\begin{frame}
\frametitle{Relation as Word Sequence}
    \begin{itemize}
        \item Relation is treated as a sequence of words from the tokenized relation name
        \item Better generalization but has difficulty learning higher-level concepts
        \item Very hard to rank \texttt{starring\_roles} higher than 
            \texttt{plays\_produced}
        \begin{itemize}
        \item Incorrect relation contains word ``plays''
        \item More similar to the question
        \end{itemize}
    \end{itemize}
    \center\includegraphics[width=0.8\textwidth]{figure/fig1}
\end{frame}

\begin{frame}
\frametitle{Proposed Improved Relation Detection}
    \begin{columns}
    \begin{column}{0.6\textwidth}
    \includegraphics[width=\textwidth]{figure/sysmodel}
    \end{column}
    \begin{column}{0.4\textwidth}
    \begin{itemize}
        \item Word-level focuses more on local information but lacks of global information
        \item Relation-level focuses more on global information but suffers from data sparsity
        \item This paper propose a hierarchical matching approach that incorporates both information levels
    \end{itemize}
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\frametitle{Relation Representation from Different Granularities}
    \begin{itemize}
        \item Tokenize input relation as 
            $$\mathbf{r}=\{r_1^{word},r_2^{word},\ldots,r_{M_1}^{word}\}\cup
            \{r_1^{rel},r_2^{rel},\ldots,r_{M_2}^{rel}\}$$
        \item first $M_1$ tokens are words and last $M_2$ tokens are relation names
        \item Transform each token to its word/relation embedding
        \item Then find hidden representation for the relation sequence
            $$[\mathbf{B}_{1:M_1}^{word}:\mathbf{B}_{1:M_1}^{rel}]$$
            via two BiLSTMs
        \item Initialize relation sequence LSTMs with the final state representations of the word sequence
        \item Apply max-pooling to these two sets of vectors and get the final relation representation $\mathbf{h}^r$
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Different Abstraction of Questions Representations}
    \begin{itemize}
        \item Question representation vectors should summarize various 
            length phrases to match relation representations of different 
            granularity
        \item Achieved via applying deep BiLSTM on questions
        \item First layer works on word embeddings, converts question words
            $\mathbf{q}=\{q_1,\ldots,q_N\}$
            to hidden representation 
            $\mathbf{\Gamma}_{1:N}^{(1)}=[\gamma_1^{(1)},\ldots,\gamma_N^{(1)}]$
        \item Second layer convert $\mathbf{\Gamma}_{1:N}^{(1)}$ 
            to $\mathbf{\Gamma}_{1:N}^{(2)}$
        \item $\mathbf{\Gamma}_{1:N}^{(1)}$ and $\mathbf{\Gamma}_{1:N}^{(2)}$ 
            could potentially match to either level of relation representation
        \item Need additional methods to reduce training difficulty
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Hierachical Matching between Relation and Questions}
    \begin{itemize}
        \item Two levels of question hidden representation are not 
            guaranteed to be comparable
        \item Training deep BiLSTM is difficult - use residual connections between layers
        \item This paper proposed two ways of Hierarchical Residual Matching
        \begin{itemize}
            \item Connecting $\gamma_i^{(1)}$ and $\gamma_i^{(1)}$ gives
                $\gamma_i^\prime=\gamma_i^{(1)} + \gamma_i^{(2)}$, and the final question
                representation $\mathbf{h}^q$ becomes a max-pooling of all $\gamma_i^\prime$
            \item Applying max-pooling to $\mathbf{\Gamma}_{1:N}^{(1)}$,
                $\mathbf{\Gamma}_{1:N}^{(2)}$  we get 
                $$\mathbf{h}^q=\mathbf{h}_{max}^{(1)}+\mathbf{h}_{max}^{(1)}$$
        \end{itemize}
        \item Matching score between relation and question is
            $$s_{rel}(\mathbf{r};\mathbf{q})=\cos(\mathbf{h}^r,\mathbf{h}^q)$$
        \item Ranking loss between golden relation $\mathbf{r}^+$ and other relations $\mathbf{r}^-$
            $$l_{rel}=\max\{0,\gamma-s_{rel}(\mathbf{r}^+;\mathbf{q})+s_{rel}(\mathbf{r}^-;\mathbf{q})\}$$
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Hierarchical Residual BiLSTM Model}
    \center\includegraphics[width=0.8\textwidth]{figure/sysmodel}
\end{frame}

\begin{frame}
\frametitle{KBQA Enhanced by Relation Detection}
    \begin{columns}
    \begin{column}{0.48\textwidth}
    \begin{itemize}
    \item Take an existing entify linker to produce the top-K 
        linked entities $EL_K(q)$ for question $q$
    \item Generate KB queries for $q$ following a 4-step algorithm
    \end{itemize}
    \end{column}
    \begin{column}{0.52\textwidth}
    \includegraphics[width=\textwidth]{figure/algo1}
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\frametitle{Experiment: Relation Detection}
    \onslide<1->{
    \begin{itemize}
        \item Dataset: SimpleQuestion (Bordes et al., 2015) and WebQSP (Yih et al., 2016)
        \item Each question is labeled with the ground-truth semantic parse
        \item Direct performance evaluation is possible, as well as KBQA evaluation
    \end{itemize}}
    \onslide<2>{
    \begin{tikzpicture}[remember picture,overlay]
    \ColorBox[xshift=4cm,yshift=3cm]{Single-relation KBQA task.}
    \end{tikzpicture}}
    \onslide<3>{
    \begin{tikzpicture}[remember picture,overlay]
    \ColorBox[xshift=9cm,yshift=3cm]{Multi-relation KBQA task.}
    \end{tikzpicture}}
    \onslide<4>{
    \center\includegraphics[width=\textwidth]{figure/table2}}
\end{frame}

\begin{frame}
\frametitle{Experiment: KBQA End-Task}
    \begin{columns}
    \begin{column}{0.5\textwidth}
    \begin{itemize}
        \item Compared to baseline relation detector, proposed system improves KBQA end-task by 2\%-3\%
    \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
    \includegraphics[width=\textwidth]{figure/table3_big}
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\frametitle{Experiment: KBQA End-Task}
    \begin{columns}
    \begin{column}{0.5\textwidth}
    {\bf Strong Points:}
    \begin{itemize}
        \item Combined different granularities of KB relationship tokens
            to capture both local and global information
        \item Used shortcut connections between BiLSTMs to reduce training difficulty
        \item Hierarchical architecture learned different levels of abstraction to prevent over-fitting
    \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
    {\bf Weak Points:}
    \begin{itemize}
        \item Exact analysis of training difficulty is missing
        \item Result of ablation test is not strong
        \item Overall performance improvement is marginal
    \end{itemize}
    \end{column}
    \end{columns}
\end{frame}

\begin{frame}
\Huge{Thank You!}\\
\small{Questions?}\\
\cofeAm{0.4}{0.8}{0}{120}{-10}
\end{frame}

\end{document}
